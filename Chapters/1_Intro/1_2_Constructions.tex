\section{Invariant Constructions}

In this section, we briefly examine how ordinary linear algebraic constructions can interact with representations. We are particularly interested in the notion of \textit{invariance}, wherein a linear algebraic construction respects the structure of any representations involved.

\subsection{Direct Sums of Representations}

The most elementary operation we can think about when we have two objects is \textit{putting them together}. One of the most meaningful ways of doing so in the context of linear algebra is the direct sum of two vector spaces. It turns out that this extends rather naturally to representations.

\begin{boxdefinition}[The Direct Sum of Two Representations]\label{Ch1:Def:Dir_Sum_Reps}
    \letgvv. We define the direct sum of $\parenth{V,\rho}$ and $\parenth{V', \rho'}$ to be the pair $\parenth{V \+ V', \rho \+ \rho'}$, where $V \+ V'$ is the direct sum of $V$ and $V'$ as vector spaces and $\rho \+ \rho' : G \to \GL{V \+ V'}$ maps every $g \in G$ to the map
    \begin{align*}
        \parenth{\rho \+ \rho'}\!\parenth{g}\!\parenth{v \+ v'} &= \rho(g)(v) \+ \rho'(g)(v') \in \GL{V}
    \end{align*}
\end{boxdefinition}
\begin{proposition}
    \letgvv.
    \begin{enumerate}[label = \normalfont \arabic*., noitemsep]
        \item The direct sum $\parenth{V \+ V', \rho \+ \rho'}$ of $\parenth{V,\rho}$ and $\parenth{V', \rho'}$ is, indeed, a representation of $G$.
        \item $V$ and $V'$ are $G$-invariant subspaces\footnote{Technically, isomorphic to the subspaces $V \+ \set{0}$ and $\set{0} \+ V'$, but we overlook such distinctions.} of $V \+ V'$.
    \end{enumerate}
\end{proposition}
\begin{proof}
    \hfill
    \begin{enumerate}[noitemsep]
        \item Fix $g,h \in G$. For all $v \+ v' \in V \+ V'$,
        \begin{align*}
            \parenth{\rho \+ \rho'}\!(gh)(v \+ v') &= \rho(gh)(v) \+ \rho'(gh)(v') \\
            &= \rho(g)\!\parenth{\rho(h)(v)} \+ \rho'(g)\!\parenth{\rho'(h)(v')} \\
            &= \parenth{\rho \+ \rho'}\!(g)\!\parenth{\parenth{\rho \+ \rho'}\!(h)(v \+ v')}
        \end{align*}
        proving that $\rho \+ \rho'$ is multiplicative. Then, for any $g \in G$, $\parenth{\rho \+ \rho'}\!(g)$ has inverse $\parenth{\rho \+ \rho'}\!\parenth{g\inv}$. Hence, $\rho \+ \rho'$ is a homomorphism from $G$ to $\GL{V \+ V'}$.

        \item Fix $g \in G$ and $v \in V$. Clearly, $\parenth{\rho \+ \rho'}\!(g)(v) = \rho(g)(v)$. Since $\rho(g) \in \GL{V}$, it follows that $\rho(g)(v) \in V$. The proof that $V'$ is $G$-invariant is identical.
    \end{enumerate}
    \vspace{-1em}
\end{proof}

The above proposition gives us another reason to consider the direct sum to be an ``invariant'' construction: while it enriches both the vector space structure and the representation structure of a summand by adding another representation into the mix, it does not take anything away from the constructions that already exist.

With direct sums, we also have similar notions to reducibility.

\begin{boxdefinition}[Indecomposability]
    A nonzero representation is said to be indecomposable if it is inexpressible as a direct sum of two proper, nonzero subrepresentations.
\end{boxdefinition}
Nonzero representations that are not indecomposable are said to be decomposable.

We have a natural relationship between irreducibility and indecomposability.

\begin{proposition}\label{Ch1:Prop:Irred_implies_Indecomp}
    \letgv. If $\Vp$ is irreducible, then it is indecomposable.
\end{proposition}
\begin{proof}
    If $V = \set{0}$, then the result is vacuously true. If $V \neq \set{0}$, then if it is decomposable, it contains a proper, nonzero, $G$-invariant subspace, making it reducible.
\end{proof}

\begin{boxexample}
    Let $C_2 = \set{1, a}$ be the cyclic group of order $2$, and let $\Vp$ be the regular representation of $C_2$ over a field $K$.
    \begin{enumerate}
        \item \underline{Let $K = \C$.} Then, let $W_1 := \Span{e_1 + e_a}$ and $W_2 := \Span{e_1 - e_a}$. It is obvious that $W_1 \+ W_2 = V$, as vector spaces. Furthermore, $W_1$ and $W_2$ are both $C_2$-invariant. Hence, $W_1 \+ W_2 = V$ as representations, too. One would say that the regular representation of $C_2$ over $\C$ is decomposable.
        \item \underline{Let $K = \F_2$.} Then, $V = \set{0, e_1, e_a, e_1 + e_a}$. Observe that $W := \set{0, e_1 + e_a}$ is a proper, $C_2$-invariant subspace of $V$. Hence, $\Vp$ is reducible. However, $W$ is the \textit{only} such subspace, meaning $\Vp$ cannot be expressed as a direct sum of \textit{two} proper, nonzero subrepresentations. Therefore, $\Vp$ is indecomposable. % In particular, \textit{the converse of Proposition \ref{Ch1:Prop:Irred_implies_Indecomp} is false}.
    \end{enumerate}
\end{boxexample}
The $K = \F_2$ case in the above example demonstrates an important fact: \textit{the converse of Proposition \ref{Ch1:Prop:Irred_implies_Indecomp} is not, in general, true.} It is natural to wonder if we can, at least, prove a \textit{partial} converse. It turns out that we can: the converse is true under a specific condition that is far from obvious. We do not yet have the tools we need to prove this result, but we will build a chain of implications, culminating in a famous theorem proved by Heinrich Maschke.

Finally, just like in other areas of mathematics where we encounter the word ``irreducible,'' in the context of representation theory, too, we have a notion of decomposition into irreducibles.

\begin{boxdefinition}[Complete Reducibility]\label{Ch1:Def:Comp_Red}
    A representation is said to be completely reducible if it is expressible as a direct sum of irreducible (sub)representations.
\end{boxdefinition}
It is clear that complete reducibility is related to irreducibility: any irreducible representation is trivially a direct sum of one irreducible representation. It turns out that complete reducibility is also related to indecomposability.

\begin{proposition}\label{Ch1:Prop:Indecomp_implies_Irred_iff_Comp_Red}
    \letfgfv. Let $K$ be a field. All indecomposable, finite-dimensional representations of $G$ over $K$ are irreducible if and only if every finite-dimensional representation of $G$ over $K$ is completely reducible.
\end{proposition}
\begin{proof}
    \hfill
    \begin{description}
        \item[$\parenth{\implies}$] Let $\Vp$ be a finite-dimensional representation of $G$ over $K$. If $\Vp$ is indecomposable, it is irreducible, making it completely reducible. Else, $\Vp$ is decomposable, making it a direct sum of two proper, nonzero subrepresentations. We can construct an inductive argument (on $\pdim{V}$) to show that each of these subrepresentations is completely reducible. We can then conclude that $\Vp$ is completely reducible.

        \item[$\parenth{\impliedby}$] Let $\Vp$ be a finite-dimensional, indecomposable representation of $G$ over $K$. By assumption, $\Vp$ is expressible as a direct sum of irreducible representations. Since $\Vp$ is indecomposable, none of the summands can be proper or nonzero. Therefore, $\Vp$ must be a direct sum of \textit{one} irreducible representation---namely, itself.
    \end{description}
\end{proof}
It will turn out that we can use complete reducibility to fill in an important gap in the converse of Proposition~\ref{Ch1:Prop:Irred_implies_Indecomp}. To do so, we will need to better understand the theory of complete reducibility. We will do so by examining the notion of complementary subrepresentations.

\subsection{Complementary Subrepresentations}

It is a well-known fact from Linear Algebra that for any finite-dimensional vector space $V$, for any subspace $W \leq V$, there exists a \textit{complementary} subspace $W' \leq V$ such that $W \+ W' = V$. As it turns out, we can define a notion of complementarity for representations, too.
\begin{boxdefinition}[Complementary Subrepresentation]
    \letgv. Let $\parenth{W, \rho\vert_W}$ be a subrepresentation of $\parenth{V, \rho}$. A complementary subrepresentation of $\parenth{W, \rho\vert_W}$ is a subrepresentation $\parenth{U, \rho\vert_U}$ such that $V = U \+ W$.
\end{boxdefinition}
This notion of complementarity is, indeed, compatible with the notion of direct sums of representations.
\begin{proposition}
    \letgv. Let $\parenth{W, \rho\vert_W}$ and $\parenth{U, \rho\vert_U}$ be complementary subrepresentations. Then, their direct sum $\parenth{V, \rho\vert_W \+ \rho\vert_U}$ is equivalent to $\parenth{V, \rho}$ as a representation of $G$.
\end{proposition}
\begin{proof}
    It suffices to show that $\rho = \rho\vert_W \+ \rho\vert_U$. Then, the identity map would give an equivalence of representations. Indeed, every $v \in V$ is expressible uniquely as a direct sum $w \+ u$ for some $w \in W$ and $u \in U$. So, for all $g \in G$,
    \begin{align*}
        \rho(g)(v) &= \rho(g)(w \+ u) \\
        &= \rho(g)(w) \+ \rho(g)(u) \\
        &= \rho\vert_W(g)(w) \+ \rho\vert_U(g)(u) \\
        &= \parenth{\rho\vert_W \+ \rho\vert_U}\!(g)(w \+ u)
    \end{align*}
    where the sum in the second equality is direct because $W$ and $U$ are $\rho(g)$-invariant.
\end{proof}

We now recall an important result from Linear Algebra.

\begin{definition}[Projection]
    Let $V$ be a vector space and let $T : V \to V$ be linear. Observe that we have the following equivalence:
    \begin{align}
        T^2 = T &\iff \forall w \in \pim{T},\ T(w) = w \label{Ch1:Eq:Proj_Op_Equiv}
    \end{align}
    If $T$ satisfies either one of the above conditions, $T$ is said to be a projection.
\end{definition}

We do not prove \eqref{Ch1:Eq:Proj_Op_Equiv}, but we do prove the following lemma, which will prove to be useful.

\begin{lemma} \label{Ch1:Lem:LinAlg_Proj_Dsum}
    Let $V$ be a vector space. For all projections $T : V \to V$, $V = \pker{T} \+ \pim{T}$.
\end{lemma}
\begin{proof}
    Let $T : V \to V$ be a projection. We then have the following.
    \begin{description}
        \item[\underline{$\pim{T} \cap \pker{T} = \set{0}$:}] Fix $w \in \pim{T} \cap \pker{T}$. Since $w \in \pim{T}$, $\exists v \in V$ such that $w = T(v)$. Furthermore, since $w \in \pker{T}$, $T(w) = 0$. Since $w = \Tof{v}$, this is equivalent to saying that $\Tof{\Tof{v}} = 0$. But, by \eqref{Ch1:Eq:Proj_Op_Equiv}, $\Tof{\Tof{v}} = \Tof{v}$. Hence, $\Tof{v} = 0$. Then, since $\Tof{v} = w$, it follows that $w = 0$.
        \item[\underline{$V = \pker{T} + \pim{T}$:}] Fix $v \in V$. We write $v = \Tof{v} + \parenth{v - \Tof{v}}$. Clearly, $\Tof{v} \in \pim{T}$. Further, $\Tof{v - \Tof{v}} = \Tof{v} - \Tof{v} = 0$. Hence, $v - \Tof{v} \in \pker{T}$.
    \end{description}
    Therefore, we do, indeed, have $V = \pker{T} \+ \pim{T}$.
\end{proof}

It turns out that this gives us an important criterion for decomposability.

\begin{corollary}\label{Ch1:Cor:G_lin_proj_ker_im}
    \letgv. If $T : \Vp \to \Vp$ is a $G$-linear projection, then $V = \pker{T} \+ \pim{T}$ is a direct sum of subrepresentations.
\end{corollary}
\begin{proof}
    The result follows immediately from Lemma \ref{Ch1:Lem:LinAlg_Proj_Dsum} and Proposition \ref{Ch1:Prop:ker_im_subreps}.
\end{proof}

One also has a converse criterion for $G$-linearity.

\begin{proposition}\label{Ch1:Prop:Proj_Inv_Lin}
    \letgv, and let $T : V \to V$ be a projection. If $\pker{T}$ and $\pim{T}$ are both $G$-invariant, then $T$ is $G$-linear.
\end{proposition}
\begin{proof}
    Since $T$ is a projection, we know that $V = \pker{T} \+ \pim{T}$. Now, fix $g \in G$ and $v \in V$. We know $v$ can uniquely be expressed as $u + w$, where $u \in \pker{T}$ and $w \in \pim{T}$. Then,
    \begin{align*}
        \Tof{\rho(g)(v)} &= \Tof{\underbrace{\rho(g)(u)}_{\in \pker{T}} + \underbrace{\rho(g)(w)}_{\in \pim{T}}} \\
        &= \rho(g)(w) \\
        &= \rho(g)\!\parenth{\Tof{v}}
    \end{align*}
    proving that $T$ is, indeed, $G$-linear.
\end{proof}

\begin{boxexample}
    Consider the situation in Example \ref{Ch1:Eg:Cyclic_Subrep}. As we discussed briefly at the beginning of Subsection \ref{Ch1:Subsec:Subreps}, we can view $\Vp$ as a subrepresentation of $\parenth{V', \rho'}$. Now, consider the linear map $S : V' \to V' : \parenth{x,y,z} \mapsto \parenth{x,y,0}$, where $\parenth{x,y,z}$ are coordinates with respect to the standard basis. This is clearly a projection operator with image $V$, the $\parenth{x,y}$ plane, and kernel the $z$-axis. These are both clearly $G$-invariant, making $S$ a $G$-linear projection.
\end{boxexample}

Finally, we relate complementary subrepresentations and complete reducibility, which makes it clear why we are so interested in complementary subrepresentations.

\begin{proposition}\label{Ch1:Prop:Compl_Subreps_implies_Comp_Red}
    \letfgfnzv. Assume that every subrepresentation of $\Vp$ admits a complementary subrepresentation. Then, $\Vp$ is completely reducible.
\end{proposition}
\begin{proof}
    We argue by induction on $\pdim{V}$. If $\pdim{V} = 1$, then $\Vp$ is irreducible, making it completely reducible. Now, assume that the statement holds for all representations of degree less than $\pdim{V}$. If $V$ is irreducible, we are done. Else, there exists a proper, nonzero, $G$-invariant subspace $W \leq V$. By assumption, $W$ admits a complementary subrepresentation $U \leq V$. By induction, $W$ and $U$ are completely reducible. Hence, $V = W \+ U$ is completely reducible.
\end{proof}

\begin{comment}
\begin{proposition}\label{Ch1:Prop:Comp_Red_iff_Compl_Subreps}
    A finite-dimensional representation of a finite group is completely reducible if and only if each of its subrepresentations admits a complementary subrepresentation.
\end{proposition}
\begin{proof}
    \letfgfv.
    \begin{description}
        \item[$\parenth{\implies}$] Assume $\Vp$ is completely reducible, with decomposition $V = \bigoplus_{i \in \I} W_i$ into irreducible subrepresentations. Let $U \leq V$ be $G$-invariant. Define $U_i := U \cap W_i$ for all $i \in \I$. Each $U_i$ is $G$-invariant, making it a subrepresentation of $W_i$. As the $W_i$s are irreducible, each $U_i$ is either $\set{0}$ or $W_i$. Now, let $\J := \set{i \in \I : U_i = W_i}$. 
        
        \item[$\parenth{\impliedby}$] Assume every subrepresentation of $\Vp$ admits a complementary subrepresentation. We know that $\Vp$ is either irreducible, in which case we'd be done, or reducible, in which case there exists a proper, nonzero, $G$-invariant subspace $W \leq V$. We know that $W$ admits a complementary subrepresentation $U \leq V$, which must also be proper and nonzero. We can argue by induction on the dimension to completely reduce both $W$ and $U$ (ie, express them as direct sums of irreducibles). We can then conclude that $\Vp$ is completely reducible.
    \end{description}
\end{proof}
\end{comment}

\subsection{Maschke's Theorem}

Given the theme of this section---namely, understanding the compatibility of ordinary linear-algebraic constructions with representation structures---one might wonder under what conditions (if any) we have the existence of a complementary subrepresentations. The answer lies in Maschke's Theorem, which is the first major result of the course.

\begin{boxtheorem}[Maschke's Theorem] \label{SP:Thm:Maschke}
    \letfg, $K$ a field such that $\pchar{K} \nmid \abs{G}$, and $\Vp$ a representation of $G$ over $K$. Then, any subrepresentation of $V$ admits a complementary subrepresentation.
\end{boxtheorem}
\begin{proof}
    Let $W \leq V$ be $G$-invariant. The idea is to construct a $G$-linear map from $V$ to $V$ with image $W$. Then, by Corollary \ref{Ch1:Cor:G_lin_proj_ker_im}, its kernel would give a complementary subrepresentation.

    From Linear Algebra, we know that $W$ admits a complementary (but not necessarily $G$-invariant) subspace $U \leq V$. Then, every $v \in V$ can uniquely be expressed as a sum $u + w$, where $u \in U$ and $w \in W$. Define $T : V \to V : u + w \mapsto w$. Clearly, $T$ is a projection operator with image $W$ and kernel $U$.

    If $T$ were $G$-linear, we would be done with the proof; unfortunately, $T$ does not have to be $G$-linear. We therefore ``convert'' $T$ into a $G$-linear projection $S : V \to V$ by \textit{averaging over $G$}. Specifically, define
    \begin{align}
        S := \frac{1}{\abs{G}} \sum_{g \in G} \rho(g) \circ T \circ \rho(g)\inv \label{Ch1:Eq:Avging_Maschke_Pf}
    \end{align}
    which is well-defined because $\abs{G} \neq 0$ in $K$. We then show the following.
    \begin{description}
        \item[\underline{$S$ is a projection with image $W$.}] Fix $v \in V$ and express it as $u + w$ for a unique $u \in U$ and $w \in W$. Then, for all $g \in G$,
        \begin{itemize}[label = $-$, noitemsep]
            \item $\Tof{\rho(g)\inv(v)} \in W$ because $T$ is a projection with image $W$.
            \item $\rho(g)\!\parenth{\Tof{\rho(g)\inv(v)}} \in W$ because $\Tof{\rho(g)\inv(v)} \in W$ and $W$ is $G$-invariant.
        \end{itemize}
        Combined with the fact that $W$ is closed under addition, this proves that $\pim{S} \subseteq W$. Conversely, for all $w \in W$ and $g \in G$,
        \begin{itemize}[label = $-$, noitemsep]
            \item $\parenth{\rho(g)\inv}\!(w) = \rhoof{g\inv}\!(w) \in W$ because $W$ is $G$-invariant.
            \item $\Tof{ \rhoof{g\inv}\!(w)} \in W$ because $ \rhoof{g\inv}\!(w) \in W$ and $W$ is $T$-invariant.
            \item $\rho(g)\!\parenth{\Tof{ \rhoof{g\inv}\!(w)}} \in W$ because $W$ is $G$-invariant.
        \end{itemize}
        Combined, again, with the fact that $W$ is closed under addition, this proves that $W \subseteq \pim{S}$. Therefore, we have that $W = \pim{S}$.

        Finally, since $T\vert_W = \id_W$, we have that $\forall w \in \pim{S} = W$,
        \begin{align*}
            S(w) &= \frac{1}{\abs{G}} \sum_{g \in G} \rho(g)\!\parenth{\Tof{\underbrace{\rho(g)\inv(w)}_{\in W}}} \\
            &= \frac{1}{\abs{G}} \sum_{g \in G} \parenth{\rho(g) \circ \rho(g)\inv}\!(w) \\
            &= \frac{1}{\abs{G}} \sum_{g \in G} w = w
        \end{align*}
        proving that $S$ is, indeed, a projection.

        \item[\underline{$S$ is $G$-linear.}]
        Fix $v \in V$ and $h \in G$. We have
        \begin{align*}
            \Sof{\rho(h)(v)} &= \frac{1}{\abs{G}} \sum_{g \in G} \parenth{\rho(g) \circ T \circ \rho(g)\inv}\!\parenth{\rho(h)(v)} \\
            &=  \frac{1}{\abs{G}} \sum_{g \in G} \parenth{\rho(g) \circ T \circ \rhoof{g\inv h}}\!(v)
        \end{align*}
        We now perform a change of variables. Observe that the map $g \mapsto h\inv g : G \to G$ is an automorphism. Hence, writing $g' = h\inv g$, we have
        \begin{align*}
            \Sof{\rho(h)(v)} &=  \frac{1}{\abs{G}} \sum_{g' \in G} \parenth{\rhoof{hg'} \circ T \circ \rhoof{\parenth{g'}\inv}}\!(v) \\
            &= \rhoof{h}\!\parenth{ \frac{1}{\abs{G}} \sum_{g' \in G} \parenth{\rhoof{g'} \circ T \circ \rhoof{g'}\inv}}\!(v) \\
            &= \rho(h)\!\parenth{\Sof{v}}
        \end{align*}
        proving that $S$ is, indeed, $G$-linear.
    \end{description}
    Therefore, by Corollary \ref{Ch1:Cor:G_lin_proj_ker_im}, $\pker{S}$ is a complementary subrepresentation of $W$.
\end{proof}

We can relate the Maschke condition to complete reducibility.

\begin{corollary} \label{Ch1:Cor:Maschke}
    \letfg, $K$ a field such that $\pchar{K} \nmid \abs{G}$. Then, every finite-dimensional representation of $G$ over $K$ is completely reducible.
\end{corollary}
\begin{proof}
    The result follows immediately from Proposition~\ref{Ch1:Prop:Compl_Subreps_implies_Comp_Red} and Theorem~\ref{SP:Thm:Maschke}.
\end{proof}

We can now prove the promised partial converse of Proposition~\ref{Ch1:Prop:Irred_implies_Indecomp}.
\begin{corollary}\label{Ch1:Cor:Indecomp_implies_Irred_of_Maschke}
    \letfg. Let $K$ be a field such that $\pchar{K}$ does not divide $\abs{G}$. Then, all indecomposable, finite-dimensional representations of $G$ over $K$ are irreducible.
\end{corollary}
\begin{proof}
    Let $\Vp$ be a finite-dimensional representation of $G$ over $K$. Corollary~\ref{Ch1:Cor:Maschke} tells us that $\Vp$ is completely reducible. We can then apply Proposition~\ref{Ch1:Prop:Indecomp_implies_Irred_iff_Comp_Red} to conclude that if $\Vp$ is indecomposable, it is irreducible.
\end{proof}

We note that both hypotheses of Maschke's Theorem---namely, that $G$ is a finite group and that $\pchar{K} \nmid \abs{G}$---are essential.

\begin{boxnexample}[When $\pchar{K} \mid \abs{G}$]
    Let $G = \cycl{a}$ be a cyclic group of prime order $p$. Let $K = \F_p$ and$V = K^2$. Define $\rho : G \to \GL{2,\F_p}$ by
    \begin{align*}
        \rhoof{a^r} &= \begin{bmatrix}
            1 & r \\ 0 & 1
        \end{bmatrix}
        \quad \text{for $r \in \F_p$.} 
    \end{align*}
    \begin{enumerate}
        \item $\Vp$ is a representation of $G$ over $\F_p$.
        \begin{proof}
            We merely need to verify that $\rho$ is, indeed, a homomorphism of groups. Fix $r,s \in \F_p$. Then,
            \begin{align*}
                \rhoof{a^r} \circ \rhoof{a^s} &= \begin{bmatrix}
                    1 & r \\ 0 & 1
                \end{bmatrix} \begin{bmatrix}
                    1 & s \\ 0 & 1
                \end{bmatrix} = \begin{bmatrix}
                    1 & s + r \\ 0 & 1
                \end{bmatrix} = \begin{bmatrix}
                    1 & r + s \\ 0 & 1
                \end{bmatrix} = \rhoof{a^{r + s}}
            \end{align*}
        \end{proof}
        \item $\Vp$ is reducible.
        \begin{proof}
            Clearly, the subspace $W := \F_p \+ \set{0}$ is proper and nonzero. Further, for all $a^r \in G$ and $x \in \F_p$, we have
            \begin{align*}
                \rhoff{a^r}{x \+ 0} =
                \begin{bmatrix}
                    1 & r \\ 0 & 1
                \end{bmatrix}
                \begin{bmatrix}
                    x \\ 0
                \end{bmatrix}
                = \begin{bmatrix}
                    x \\ 0
                \end{bmatrix} \in W
            \end{align*}
            showing not only that $W$ is $G$-invariant but also that the corresponding subrepresentation is trivial.
        \end{proof}
        \item $W$ admits no complementary subrepresentation.
        \begin{proof}
            We will show that $W$ is the only $G$-invariant subspace of dimension $1$. Let $U \leq V$ be a $G$-invariant subspace of dimension $1$. Then, $U$ is spanned by a vector $u = \begin{bmatrix} x \\ y \end{bmatrix}$ for some $x,y \in \F_p$. Since $U$ is $G$-invariant, in particular, there must exist some $\lambda \in \F_p$ such that
            \begin{align*}
                \rhoff{a^1}{u} = 
                \begin{bmatrix}
                    1 & 1 \\ 0 & 1
                \end{bmatrix}
                \begin{bmatrix}
                    x \\ y
                \end{bmatrix}
                = \begin{bmatrix}
                    x + y \\ y
                \end{bmatrix}
                = \lambda \begin{bmatrix}
                    x \\ y
                \end{bmatrix}
            \end{align*}
            For $y$ to be equal to $\lambda y$, we must have that $\lambda = 1$. This would then imply that $x = x + y$, requiring that $y$ be $0$. Therefore, $U$ must be equal to $W$. Hence, $W$ cannot admit a complementary subrepresentation, as such a subrepresentation would have to have degree $1$, which would make it equal to $W$.
        \end{proof}
    \end{enumerate}
    This illustrates that when the hypothesis of Maschke's Theorem (ie, that $\pchar{K} \nmid \abs{G}$) fails, so too might the conclusion. Indeed, the argument above also shows $\Vp$ to be indecomposable, as any decomposition would need to involve two distinct $G$-invariant subspaces of dimension $1$. This shows that the conclusion of Corollary~\ref{Ch1:Cor:Indecomp_implies_Irred_of_Maschke} can also fail when $\pchar{K} \mid \abs{G}$. Finally, if $\Vp$ is indecomposable and reducible, it cannot be completely reducible, demonstrating that the conclusion of Corollary~\ref{Ch1:Cor:Maschke} \textit{also} fails when $\pchar{K} \mid \abs{G}$.
\end{boxnexample}

It turns out that Maschke's Theorem also has a \textit{converse}.

\begin{boxtheorem}[Converse of Maschke's Theorem] \label{Ch1:Thm:Maschke_Converse}
    \letfg\ such that every finite-dimensional representation of $G$ over some field $K$ is completely reducible. Then, $\pchar{K} \nmid \abs{G}$.
\end{boxtheorem}
\begin{proof}
    Consider the regular representation $\parenth{K[G], \rho}$ of $G$ over $K$, with basis $\B = \set{e_g : g \in G}$. The idea is to take advantage of the $G$-invariant properties of $\B$.

    Consider the subspace
    \begin{align*}
        W := \set{\sum_{g \in G} \alpha_g e_g : \sum_{g \in G} \alpha_g = 0}
    \end{align*}
    of dimension $\pdim{V} - 1$. It turns out that $W$ is $G$-invariant: for all $\sum_{g \in G} \alpha_g e_g \in W$ and $h \in G$, we have
    \begin{align*}
        \rho(h)\!\parenth{\sum_{g \in G} \alpha_g e_g} &= \sum_{g \in G} \alpha_g e_{hg} \in W
    \end{align*}
    (where the sum of the coefficients $\alpha_g$ is still zero). Then, by assumption, $\exists U \leq V$ that is both $G$-invariant and complementary to $W$. This means that $U$ must be of dimension $1$, and is hence the span of a single vector $u \in U$.

    We study the action of $G$ on $U$. Fix $h \in G$, and write $u = \sum_{g \in G} \beta_g e_g$ for $\beta_g \in K$. Then,
    \begin{align*}
        \rho(h)(u) - u
        &= \sum_{g \in G} \underbrace{\beta_g e_{hg} - \beta_g e_g}_{\in W}
    \end{align*}
    meaning that $\rho(h)(u) - u \in W$. But, $\rho(h)(u) - u \in U$ as well. Since $U \cap W = \set{0}$, this means that $\rho(h)(u) = u$ for all $h \in G$. Hence, the action of $G$ on $U$ is \textit{trivial}. Therefore, for all $x \in G$,
    \begin{align*}
        \sum_{g \in G} \beta_g e_{hg} &= \sum_{g \in G} \beta_g e_g
    \end{align*}
    Comparing coefficients, we conclude that $\beta_{h\inv g} = \beta_g$ for all $h,g \in G$. Letting $h = g$, we get, in particular, that $\forall g \in G$, $\beta_g = \beta_1$. Therefore, $u = \beta_1 \sum_{g \in G} e_g$. This, in particular, implies that $u' := \sum_{g \in G} e_g \notin W$, because otherwise, $u = \beta_1 u'$ would also lie in $W$, which it does not. Therefore, the sum of the coordinates of $u'$ with respect to $\B$ cannot be zero. But, this sum is nothing but the cardinality of $G$ (or rather, its image in the canonical map $\Z \to K$). Since this is nonzero, it must be that $\pchar{K} \nmid \abs{G}$, as required.
\end{proof}

\subsection{$G$-Invariant Inner-Products}

It turns out that we also have a notion of inner-products being compatible with representation strutures.

\begin{boxdefinition}[$G$-Invariant Inner-Product]
    \letgv\ over $\C$ such that $V$ admits an inner-product $\cycl{\cdot, \cdot}$.We say that $\cycl{\cdot, \cdot}$ is $G$-invariant if $\forall g \in G$ and $\forall x, y \in V$,
    \begin{align*}
        \cycl{x,y} &= \cycl{\rho(g)(x), \rho(g)(y)}
    \end{align*}
    Equivalently, $\cycl{\cdot, \cdot}$ is $G$-invariant if $\pim{\rho} \subseteq \U{V}$, ie, if, for every $g \in G$, $\rho(g)$ is a \textit{unitary} $\C$-linear map from $V$ to $V$.
\end{boxdefinition}

Intrinsic to the notion of an inner-product is that of orthogonality. In the following proposition, we understand the significance of $G$-invariance in the context of subrepresentations.

\begin{proposition} \label{Ch1:Prop:Orth_Compl_of_Inv_Inv}
    \letgv\ over $\C$ of finite dimension. Let $\cycl{\cdot, \cdot}$ be a $G$-invariant inner-product on $V$. Then, the orthogonal complement of any $G$-invariant subspace of $V$ is also $G$-invariant.
\end{proposition}
\begin{proof}
    Let $W \leq V$ be $G$-invariant, and denote by $W^\perp$ its orthogonal complement. Fix $g \in G$ and $w \in W^\perp$. To show that $\rhoff{g}{w} \in W^\perp$, we show it is orthogonal to every $v \in W$.

    Fix $v \in W$. Then, since $\cycl{\cdot, \cdot}$ is $G$-invariant,
    \begin{align*}
        \cycl{v, \rhoff{g}{w}} &= \cycl{\rhoff{g\inv}{v}, \rhoff{g\inv g}{w}} \\
        &= \cycl{\rhoff{g\inv}{v}, w}
    \end{align*}
    Since $W$ is $G$-invariant, $\rhoff{g\inv}{v} \in W$. Since $w \in W^\perp$, we may conclude that $\cycl{\rhoff{g\inv}{v}, w} = 0$. Therefore, $\cycl{v, \rhoff{g}{w}} = 0$ as well, proving that $\rhoff{g}{w} \in W^\perp$.
\end{proof}

\begin{corollary}
    \letgv\ over $\C$. If $V$ is finite dimensional and admits a $G$-invariant inner-product, then $V$ is completely reducible.
\end{corollary}
\begin{proof}
    If $V$ is finite dimensional and admits a $G$-invariant inner-product, then by Proposition \ref{Ch1:Prop:Orth_Compl_of_Inv_Inv}, for any $W \leq V$ $G$-invariant, $W^\perp$ is $G$-invariant as well. Since $W \+ W^\perp = V$ and both $W$ and $W^\perp$ are finite-dimensional, we can prove the result using similar reasoning to what we used to prove Corollary \ref{Ch1:Cor:Maschke}.
\end{proof}

\subsection{Tensor Products of Representations}\label{Ch1:Subsec:Tensor_Prods}

We begin by recalling the notion of a tensor product of two finite-dimensional vector spaces.

\begin{definition}[Tensor Product of Vector Spaces]
    Let $K$ be a field and let $V, W$ be finite-dimensional vector spaces over $K$ with bases $\set{v_i}$ and $\set{w_i}$ respectively. The tensor product of $V$ and $W$, denoted $V \otimes_K W$, is a vector space of dimension $\pdim{V} \pdim{W}$ with basis
    \begin{align}
        \set{v_i \otimes w_j : 1 \leq i \leq \pdim{V}, 1 \leq j \leq \pdim{W}}
    \end{align}
    such that the map
    \begin{align*}
        \otimes_K : V \times W \to V \otimes_K W :
        (v,w) \mapsto v \otimes_K w
    \end{align*}
    is bilinear.
\end{definition}
\begin{remark}
    Sometimes, when the base field (or ring) is clear from the context, we omit the subscript in the notation for the tensor product.
\end{remark}

In similar fashion to Definition \ref{Ch1:Def:Dir_Sum_Reps}, we can extend this definition to representations.

\begin{boxdefinition}[Tensor Product of Representations]
    Let $G$ be a finite group and let $\Vp$ and $\parenth{W, \rho'}$ be representations of $G$ over $K$. The tensor product of $\Vp$ and $\parenth{V', \rho'}$, denoted $\Vp \otimes \parenth{V', \rho'}$, is a representation of $G$ over $K$ with underlying set $V \times_K V'$ and action
    \begin{align*}
        \parenth{\rho \otimes_K \rho'}\!\parenth{g}\!\parenth{v \otimes_K v'} &= \rho(g)(v) \otimes_K \rho'(g)(v') \in \GL{V}
    \end{align*}
\end{boxdefinition}

We will see more of the properties of Tensor Products as we go along, primarily in Section \ref{Ch3:Sec:Products}. We do not go into more detail here as the multiplicative properties of the tensor product are best appreciated if considered alongside a well-developed theory of characters. Until then, the invariant construction whose properties we will explore in detail shall be the direct sum.